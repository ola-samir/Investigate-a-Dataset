#!/usr/bin/env python
# coding: utf-8

# 
# # Project: Investigate a Dataset - [TMDb movie data]
# 
# ## Table of Contents
# <ul>
# <li><a href="#intro">Introduction</a></li>
# <li><a href="#wrangling">Data Wrangling</a></li>

# </ul>

# <a id='intro'></a>
# ## Introduction
# 
# ### Dataset Description 
# 
# This data set contains information about 10,000 movies collected from The Movie Database (TMDb), including user ratings, revenue ,runtime and genres
# 
# Columns of the dataset:
# 
# id                      
# imdb_id                 
# popularity              
# budget                  
# revenue                 
# original_title          
# cast                    
# homepage                
# director                
# tagline                 
# keywords                
# overview                
# runtime                 
# genres                  
# production_companies    
# release_date            
# vote_count              
# vote_average            
# release_year            
# budget_adj              
# revenue_adj 
# 
# 


# In[1]:


# Use this cell to set up import statements for all of the packages that you
#   plan to use.
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
get_ipython().run_line_magic('matplotlib', 'inline')
import seaborn as sns
# Remember to include a 'magic word' so that your visualizations are plotted
#   inline with the notebook. See this page for more:
#   http://ipython.readthedocs.io/en/stable/interactive/magics.html


# 
# ## Data Wrangling
# 

# In[2]:


# Load your data and print out a few lines. Perform operations to inspect data
#   types and look for instances of missing or possibly errant data.
df = pd.read_csv('tmdb-movies.csv')


# Assessing Data
#  & Checking data set and its main characteristics

# In[3]:


df.info()


# In[4]:


df.describe()


# In[5]:


# checking data types of columns
df.dtypes


# In[6]:


# check the shape of data , number of columns and rows
df.shape


# In[7]:


df.head(3)


# In[8]:


# check for duplicates
df.duplicated().sum()


# I found that there is only 1 duplicated row . So , no need to drop it. This wouldn't affect.

# In[9]:


# check for NaN values in each columns
df.isnull().sum()


# In[10]:


# the number of unique values in each column
df.nunique()


# In[11]:


df.hist(figsize=(13,13));


# 
# ### Data Cleaning
# From the step of assessing data using some pandas functions , we realize that:
# 
# - the columns ('id','imdb_id','homepage','tagline','keywords','overview','budget_adj','revenue_adj') are not important in our analysis process , So we're going to drop them.
# 
# - the columns('budget','revenue','runtime') have many "0" values , So we're going to replace them with "NaN" values and then drop these NaN values inorder to clean our data and make the analysis more accurate.
# 

# In[12]:


# drop the columns ('id','imdb_id','homepage','tagline','keywords','overview','budget_adj','revenue_adj')
deleted_columns=['id','imdb_id','homepage','tagline','keywords','overview','budget_adj','revenue_adj']
df=df.drop(deleted_columns,1)


# In[13]:


# make sure that the columns have been deleted
df.shape


# In[14]:


# replace "0" values with "NaN" values ('budget','revenue','runtime') 

replaced_list=['budget', 'revenue','runtime']
df[replaced_list] = df[replaced_list].replace(0, np.NAN)

#Removing all the row which has NaN value in replaced_list 
df.dropna(subset =replaced_list, inplace = True)


# In[15]:


# check the shape of the data frame after removing NaN values
df.shape

# In[16]:


df.head(3)

